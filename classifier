import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import torch
from torch.utils.data import DataLoader, TensorDataset
import pandas as pd
import torch
from sklearn.decomposition import PCA

# Sample data creation (for example purposes)
# df = pd.read_csv('your_time_series_data.csv')  # Uncomment to load your data
df = pd.read_excel('xx.xlsx')
df = df.drop(['xx', 'xx'], axis = 1)

# Assuming df has a column 'label' for labels and other columns are the time series data
labels = df['xx']
data = df.drop(columns=['xx']).apply(pd.to_numeric, errors='coerce').fillna(0).values

# Encode labels to binary (1 for target_label, 0 for others)
target_label = df[df['xx'].str.contains('NAME')].iloc[0]['xx'] # Replace with your target label
# encoder = LabelEncoder()
print(np.shape(target_label))
print(target_label)
# print(target_label)
binary_labels = labels.str.contains(target_label).astype(int)
print(binary_labels)
print(np.shape(data))

# pca = PCA(n_components=5)  # Choose the number of components
# X_train_pca = pca.fit_transform(data)
# X_train_pca_tensor = torch.tensor(X_train_pca, dtype=torch.float32)
# # print(X_train_pca[0:3].shape())
# # print(np.shape(X_train_pca[0:10]))
# data = X_train_pca_tensor
# print(np.shape(data))



# occurrences = np.char.count(binary_labels, target_label)

# print(occurrences)  
# Split data
X_train, X_val, y_train, y_val = train_test_split(data, binary_labels, test_size=0.2, random_state=42)

# Convert to numpy arrays
y_train = y_train.to_numpy()
y_val = y_val.to_numpy()
print(y_val)
# Convert to PyTorch tensors
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32)
X_val_tensor = torch.tensor(X_val, dtype=torch.float32)
y_val_tensor = torch.tensor(y_val, dtype=torch.float32)

# Create DataLoader
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
val_dataset = TensorDataset(X_val_tensor, y_val_tensor)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)




import torch.nn as nn
import torch.nn.functional as F
from sklearn.utils.class_weight import compute_class_weight

class TimeSeriesCNN(nn.Module):
    def __init__(self, input_dim):
        super(TimeSeriesCNN, self).__init__()
        self.conv1 = nn.Conv1d(1, 32, kernel_size=5, padding=1)
        self.conv2 = nn.Conv1d(32, 32, kernel_size=3, padding=1)
        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(64 * 1, 100)
        self.fc2 = nn.Linear(100, 1)
    
    def forward(self, x):
        x = x.unsqueeze(1)  # Add channel dimension
        x = F.relu(self.conv1(x))
        x = F.max_pool1d(x, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool1d(x, 2)
        x = F.relu(self.conv3(x))
        x = F.max_pool1d(x, 2)
        x = x.view(x.size(0), -1)  # Flatten
        x = F.relu(self.fc1(x))
        x = torch.sigmoid(self.fc2(x))
        return x

input_dim = X_train.shape[1]  # Number of features in the time series
model = TimeSeriesCNN(input_dim)



import torch.optim as optim

criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

num_epochs = 20

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs.squeeze(), labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * inputs.size(0)
    
    epoch_loss = running_loss / len(train_loader.dataset)
    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')
    
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for inputs, labels in val_loader:
            outputs = model(inputs)
            loss = criterion(outputs.squeeze(), labels)
            val_loss += loss.item() * inputs.size(0)
    
    val_loss = val_loss / len(val_loader.dataset)
    print(f'Validation Loss: {val_loss:.4f}')



from sklearn.metrics import accuracy_score, f1_score, roc_auc_score

model.eval()
val_preds = []
val_labels = []

with torch.no_grad():
    for inputs, labels in val_loader:
        outputs = model(inputs)
        preds = (outputs.squeeze() > 0.5).float()
        val_preds.extend(preds.cpu().numpy())
        val_labels.extend(labels.cpu().numpy())

accuracy = accuracy_score(val_labels, val_preds)
f1 = f1_score(val_labels, val_preds)
roc_auc = roc_auc_score(val_labels, val_preds)

print(f'Validation Accuracy: {accuracy:.4f}')
print(f'Validation F1 Score: {f1:.4f}')
print(f'Validation ROC AUC Score: {roc_auc:.4f}')


true_labels = []
predicted_labels = []

# Iterate over the validation DataLoader to collect true labels
for inputs, labels in val_loader:
    true_labels.extend(labels.numpy())

# Convert true labels to a numpy array
true_labels = np.array(true_labels)

# Iterate over the model predictions to collect predicted labels
for inputs, labels in val_loader:
    outputs = model(inputs)
    preds = (outputs.squeeze() > 0.5).float().cpu().numpy()
    predicted_labels.extend(preds)

# Convert predicted labels to a numpy array
predicted_labels = np.array(predicted_labels)

# Create a DataFrame with true labels and predicted labels
df_results = pd.DataFrame({'True_Label': true_labels, 'Predicted_Label': predicted_labels})

# Display the DataFrame
print(df_results)
